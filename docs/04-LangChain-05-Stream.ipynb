{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b73e98",
   "metadata": {},
   "source": [
    "# LangChain流式处理\n",
    "\n",
    "由于大部分任务LLM没有办法立即给出输出结果，所谓为了更好的用体验，在处理和用户交互任务或者日志打印进度时，需要考虑流式处理。\n",
    "\n",
    "## 支持的流式处理的模式\n",
    "\n",
    "1. values： 每个步骤之后都会打印完整值\n",
    "2. updates: 只输出在节点中state有变化的值\n",
    "3. custom: 从图形节点内部流式传输自定义数据\n",
    "4. messages: 只输出在节点中调用LLM\n",
    "5. debug: 打印每个节点更详细的信息\n",
    "\n",
    "## 代理进度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6d7844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.tools import tool\n",
    "@tool\n",
    "def get_weather(city:str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\"\n",
    ")\n",
    "from langchain.agents import create_agent\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather]\n",
    ")\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=\"updates\"\n",
    "):\n",
    "    for step, data in chunk.items():\n",
    "        print(f\"step: {step}\")\n",
    "        print(f\"content: {data['messages'][-1].content_blocks}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a575a0",
   "metadata": {},
   "source": [
    "## LLM Tokens\n",
    "\n",
    "要流式传输 LLM 生成的令牌，请使用 stream_mode=\"messages\"。下面您可以看到代理流式传输工具调用和最终响应的输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4b49f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.tools import tool\n",
    "@tool\n",
    "def get_weather(city:str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\"\n",
    ")\n",
    "from langchain.agents import create_agent\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather]\n",
    ")\n",
    "for token, metadata in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=\"messages\"\n",
    "):\n",
    "    print(f\"node: {metadata['langgraph_node']}\")\n",
    "    print(f\"content: {token.content_blocks}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d51627",
   "metadata": {},
   "source": [
    "## 自定义更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5877e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.tools import tool\n",
    "from langgraph.config import get_stream_writer  \n",
    "@tool\n",
    "def get_weather(city:str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    writer = get_stream_writer()  \n",
    "    # stream any arbitrary data\n",
    "    writer(f\"Looking up data for city: {city}\")\n",
    "    writer(f\"Acquired data for city: {city}\")\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\"\n",
    ")\n",
    "from langchain.agents import create_agent\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather]\n",
    ")\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=\"custom\"\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6170c84",
   "metadata": {},
   "source": [
    "## 流式传输多种模式\n",
    "\n",
    "您可以通过将流模式作为列表传递来指定多个流模式：stream_mode=[\"updates\", \"custom\"]。\n",
    "\n",
    "流式传输的输出将是 (mode, chunk) 元组，其中 mode 是流模式的名称，而 chunk 是该模式流式传输的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1bf5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.tools import tool\n",
    "from langgraph.config import get_stream_writer  \n",
    "@tool\n",
    "def get_weather(city:str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    writer = get_stream_writer()  \n",
    "    # stream any arbitrary data\n",
    "    writer(f\"Looking up data for city: {city}\")\n",
    "    writer(f\"Acquired data for city: {city}\")\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "llm = ChatDeepSeek(\n",
    "    model=\"deepseek-chat\"\n",
    ")\n",
    "from langchain.agents import create_agent\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[get_weather]\n",
    ")\n",
    "for stream_mode, chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"updates\", \"custom\"]\n",
    "):\n",
    "    print(f\"stream_mode: {stream_mode}\")\n",
    "    print(f\"content: {chunk}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
